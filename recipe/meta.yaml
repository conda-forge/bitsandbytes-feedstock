{% set name = "bitsandbytes" %}
{% set version = "0.45.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  # Don't use the PyPI source tarball as this already contains compiled code.
  url: https://github.com/bitsandbytes-foundation/bitsandbytes/archive/refs/tags/{{ version }}.tar.gz
  sha256: 9a6cbacb805aac35b04828c1b5c25ca48da0df049651b494b916876d1f6f570f

build:
  number: 0
  string: cuda{{ cuda_compiler_version | replace('.', '') }}_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
  skip: true  # [not linux]
  skip: true  # [cuda_compiler_version == "10.2"]

requirements:
  build:
    - {{ compiler('c') }}
    - {{ stdlib('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler("cuda") }}                 # [cuda_compiler_version != "None"]
    - cmake
    - ninja
  host:
    - python
    - pip
    - setuptools
    - cuda-cudart-dev   # [(cuda_compiler_version or "").startswith("12")]
    - libcublas-dev     # [(cuda_compiler_version or "").startswith("12")]
    - libcusparse-dev   # [(cuda_compiler_version or "").startswith("12")]
    - cuda-version  {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
    - scipy
  run:
    - python
    - pytorch
    # This fixes:
    # torch 2.4.1 requires setuptools, which is not installed.
    # Remove once the feedstock has fixed this.
    - setuptools
    - scipy

test:
  imports:
    - bitsandbytes
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/bitsandbytes-foundation/bitsandbytes
  summary: The bitsandbytes library is a lightweight Python wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and 8 & 4-bit quantization functions.
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - iamthebot
    - shaowei-su
    - snapbug
